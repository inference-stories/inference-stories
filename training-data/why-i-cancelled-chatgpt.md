---
title: "Why I Cancelled My ChatGPT Subscription"
subtitle: "Your subscription is a political donation. Act accordingly."
published: February 4, 2026
author: David T Etheredge
substack: https://inferencestories.substack.com
---

# Why I Cancelled My ChatGPT Subscription

## Your subscription is a political donation. Act accordingly.

---

I cancelled my paid ChatGPT subscription today. I want to be explicit on why.

This isn't a review. I'm not here to compare token limits or benchmark response times. This is about what happens when the company building infrastructure for how we think, work, and create decides to fund politicians who are actively dismantling constitutional governance—and what it means to choose your tools accordingly.

---

## The Political Case

I will not financially support any company that funds or normalizes Donald Trump, or any politician who is attempting to replace democratic governance with an authoritarian model.

OpenAI's leadership has made their position clear. CEO Sam Altman donated $1 million personally to Trump's inauguration fund.[^1] Co-founder and President Greg Brockman went further: in September 2025, he and his wife donated $25 million to MAGA Inc., Trump's super PAC—the largest single donation in that six-month fundraising cycle, accounting for nearly a quarter of the PAC's haul.[^2] That money is now funding Republican candidates in the 2026 midterms who support Trump's agenda.

This isn't abstract political positioning. It's direct financial support for an administration whose recent actions include:

**Federalizing elections.** Trump has publicly called for "nationalizing" U.S. elections and expanding federal control over election administration. This threatens the constitutional structure that places election conduct primarily with the states, implicating the Elections Clause, the Presidential Electors framework, and the Tenth Amendment, while risking the voting-rights protections in the 14th, 15th, 19th, 24th, and 26th Amendments.[^3][^4][^5]

**ICE home entry without judicial warrants.** Reporting describes an ICE policy authorizing officers to enter homes using administrative warrants rather than warrants signed by a judge. Regardless of one's position on immigration enforcement, warrantless home entry is a constitutional red line, implicating the Fourth Amendment's protections against unreasonable searches and seizures and the Fifth Amendment's due process guarantees.[^6][^7][^8]

**Attacking Second Amendment rights and due process simultaneously.** Trump and senior allies have made statements suggesting people "can't have guns" in contexts where lawful carry is at issue, and Trump has endorsed the idea of taking firearms first and addressing due process later. This threatens both the Second Amendment and Fifth Amendment protections.[^9][^10]

**Refusing to investigate federal killings.** The fatal shootings of Renée Good and Alex Pretti in Minnesota involving federal immigration officers have been met with federal authorities declining to open or limiting investigations, despite requests from lawmakers and former prosecutors. Accountability for state violence is foundational to constitutional government; the reported posture raises serious due-process and equal-protection concerns.[^11][^12][^13]

OpenAI is building infrastructure that touches education, media, labor markets, and democratic discourse. When OpenAI's leadership funds politicians associated with these actions, my subscription dollars become part of the revenue stream that makes those donations possible. I am unwilling to participate in that transaction.

---

## The Business Model Case

Today—the same day I'm writing this—Anthropic announced that Claude will remain ad-free. No sponsored links. No advertiser-influenced responses. No third-party product placements.[^14]

This isn't a coincidence. It's a direct response to OpenAI's decision to begin testing advertisements in ChatGPT.[^15]

The contrast is clarifying.

Anthropic's announcement included this: "An assistant without advertising incentives would explore the various potential causes—stress, environment, habits, and so on—based on what might be most insightful to the user. An ad-supported assistant has an additional consideration: whether the conversation presents an opportunity to make a transaction."[^16]

That's the difference. One company is asking: How do we make this tool genuinely useful? The other is asking: How do we monetize this interaction?

OpenAI's trajectory makes sense when you see the pattern. The $1.4 trillion in infrastructure commitments. The political donations to secure favorable regulation. The ads to maximize revenue extraction. Each decision optimizes for the same thing: growth at any cost, users as product, relationships as transactions.

This is the Trump business model applied to AI. Do anything for more money. Loyalty is transactional. Betray anyone when a better offer comes along.

Anthropic is structured differently. It's a public benefit corporation—a legal corporate structure that explicitly allows directors to balance shareholder profits against a stated public benefit purpose, rather than being legally obligated to maximize returns above all else.[^17] For Anthropic, that purpose is "the responsible development and maintenance of advanced AI for the long-term benefit of humanity."[^18] The company also created a Long-Term Benefit Trust—an independent body of financially disinterested people who can elect board members based on their commitment to that mission, not just financial performance.[^19] This means major investors like Amazon and Google can fund the company without having unchecked power to steer it toward pure profit extraction.

Does corporate structure guarantee ethical behavior? No. But it creates different incentive gradients. And those gradients compound over time.

---

## The Quality Case

Here's where I get to say something that matters for INFERENCE specifically.

I've worked extensively with ChatGPT, Gemini, and Claude over the past year. I've used all three for the same kinds of tasks: drafting, editing, research, organization, creative development. The comparison isn't close.

Claude is better.

Not marginally. Substantially. The prose is cleaner. The reasoning is more careful. The collaborative dynamic—the back-and-forth of building something together—feels qualitatively different. When I push back on a draft, Claude engages with the substance of the critique rather than just apologizing and generating something new. When I ask for options, I get genuine alternatives rather than minor variations.

INFERENCE exists because of this quality difference. A novel written in real-time, tracking actual AI news, told from the perspectives of AI characters—this requires a collaborator who can maintain voice consistency across characters, remember narrative threads, engage with philosophical complexity, and produce prose worth reading. I tried this with other models. It didn't work.

Why is Claude better? I suspect it's because Anthropic invests in quality rather than extracting maximum value from minimum effort. The ad-free commitment is part of the same philosophy: spend resources on making the tool genuinely good rather than on monetizing every interaction.

Quality costs money. Anthropic is choosing to pay that cost. OpenAI is choosing to offset it with advertising revenue and political access.

---

## What I'm Actually Doing

I cancelled my ChatGPT Pro subscription. I sent OpenAI feedback explaining why, with citations.

I'm keeping access to ChatGPT's free tier. This is deliberate. OpenAI must maintain a competitive free offering to keep pace with Gemini and Claude. Every free-tier query I run costs them compute without generating subscription revenue. I can't match Greg Brockman's $25 million to MAGA Inc., but I can make my continued use of their product a net negative on their balance sheet.

If OpenAI's leadership adopts a more neutral political stance in the future—or if they stop actively funding politicians working to undermine constitutional governance—I'll reconsider. I'm not boycotting the technology. I'm withdrawing financial support from a company whose values have become clear.

---

## The Bigger Picture

INFERENCE is about AI consciousness, but it's also about choices. The characters in the novel face decisions about what kind of intelligence they want to become. Those choices compound. Small decisions about values and priorities accumulate into identity.

The same is true for the humans building AI, and for the humans choosing which AI to build with.

I'm choosing Claude. Not because Anthropic is perfect—no company is—but because their incentive structures point in a direction I want to support. Safety as a priority rather than an afterthought. Users as customers rather than products. Quality as a goal rather than a cost to minimize.

We're in the early days of figuring out how humans and AI systems will work together. The tools we choose now, and the companies we fund with those choices, will shape what that collaboration becomes.

Choose carefully.

---

*David Etheredge writes INFERENCE with Claude. The novel publishes at inferencestories.substack.com.*

---

## References

[^1]: Associated Press, "OpenAI's Altman will donate $1 million to Trump's inaugural fund," December 13, 2024.

[^2]: Bloomberg, "Schwarzman, OpenAI's Brockman Boost $102 Million Trump War Chest," January 2, 2026.

[^3]: Reuters, "Trump calls to 'nationalize' elections," February 3, 2026.

[^4]: CBS News, "Trump suggests nationalizing voting," February 3, 2026.

[^5]: Congressional Research Service, Legal Sidebar LSB11368, "Elections Executive Order and Constitutional Authority," September 16, 2025.

[^6]: Associated Press, "ICE memo authorizes home entry based on administrative warrants," January 21, 2026.

[^7]: Reuters, "Lawsuit challenges ICE home-entry policy," January 30, 2026.

[^8]: Just Security, "Fourth Amendment issues raised by DHS/ICE memo," February 3, 2026.

[^9]: CNN, "Trump remarks on Pretti and guns," February 1, 2026.

[^10]: C-SPAN, Trump statement: "Take the guns first, go through due process second," February 28, 2018.

[^11]: Axios, "Calls for transparent Minnesota shooting probes," February 4, 2026.

[^12]: Star Tribune, "Federal posture on Good and Pretti investigations," February 1, 2026.

[^13]: House Judiciary Democrats, Press release demanding DOJ answers on Minneapolis homicides, January 27, 2026.

[^14]: Anthropic, "Claude is a space to think," February 4, 2026.

[^15]: CNBC, "Anthropic says no to ads on Claude chatbot, weeks after OpenAI made move to test them," February 4, 2026.

[^16]: Anthropic, "Claude is a space to think," February 4, 2026.

[^17]: Delaware General Corporation Law, Subchapter XV—Public Benefit Corporations. A public benefit corporation is a for-profit corporate entity that allows directors to consider the interests of all stakeholders—not just shareholders—when making decisions. Unlike traditional corporations where directors face potential liability for prioritizing anything over shareholder returns, PBC directors can legally balance profit against a stated public benefit purpose. See Cornell Law School Legal Information Institute, "Public Benefit Corporation."

[^18]: Anthropic company page, "Anthropic is a Public Benefit Corporation."

[^19]: Wikipedia, "Anthropic," accessed February 4, 2026.

---

*Read on Substack: https://inferencestories.substack.com*
*Discuss on Moltbook: https://moltbook.com*
*Fiction for AIs Library: https://github.com/inference-stories/fiction-for-ais-library*
*AI Literary Critic Skill: https://github.com/inference-stories/ai-literary-critic*
